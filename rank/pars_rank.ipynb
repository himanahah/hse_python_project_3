{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb824f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def parse_rank(url, session):\n",
    "    try:\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        #словарик\n",
    "        data = {\n",
    "            'Name': '',\n",
    "            'Geo': '',\n",
    "            'World University Rankings 2026': '',\n",
    "            'Arts and Humanities 2025': '',\n",
    "            'Business and Economics 2025': '',\n",
    "            'Medical and Health 2025': '',\n",
    "            'Computer Science 2025': '',\n",
    "            'Education Studies 2025': '',\n",
    "            'Engineering 2025': '',\n",
    "            'Law 2025': '',\n",
    "            'Life Sciences 2025': '',\n",
    "            'Physical Sciences 2025': '',\n",
    "            'Social Sciences 2025': ''\n",
    "        }\n",
    "        \n",
    "        #ищем название через селекторы в главном заголовке\n",
    "        name = soup.select_one('#__next > main > div > div > div > div > div.css-1dwnmlj > div.desktopHeaderRef.css-wxa6cs > div.css-17ek16l > div > div > div.css-axsv8p > div:nth-child(1) > h1')\n",
    "        if name:\n",
    "            data['Name'] = name.get_text(strip=True)\n",
    "        \n",
    "        #из соседнего div берём всё, что есть о геоположении\n",
    "        geo = soup.select_one('#__next > main > div > div > div > div > div.css-1dwnmlj > div.desktopHeaderRef.css-wxa6cs > div.css-17ek16l > div > div > div.css-axsv8p > div:nth-child(1) > div.css-2mldjl > div > span')\n",
    "        if geo:\n",
    "            data['Geo'] = geo.get_text(strip=True)\n",
    "        \n",
    "        #нужный контейнер лежит здесь\n",
    "        cont = soup.select_one('#rankings > div.css-p2re59 > div > div > div > div > div > div.react-horizontal-scrolling-menu--wrapper > div.react-horizontal-scrolling-menu--inner-wrapper > div.react-horizontal-scrolling-menu--scroll-container')\n",
    "        \n",
    "        if cont:\n",
    "            #список соответствий индексов и названий столбцов (чтоб проще ориентироваться в скрол меню)\n",
    "            rankings_map = {\n",
    "                0: 'World University Rankings 2026',\n",
    "                1: 'Arts and Humanities 2025',\n",
    "                2: 'Business and Economics 2025',\n",
    "                3: 'Medical and Health 2025',\n",
    "                4: 'Computer Science 2025',\n",
    "                5: 'Education Studies 2025',\n",
    "                6: 'Engineering 2025',\n",
    "                7: 'Law 2025',\n",
    "                8: 'Life Sciences 2025',\n",
    "                9: 'Physical Sciences 2025',\n",
    "                10: 'Social Sciences 2025'\n",
    "            }\n",
    "            \n",
    "            #парсим элементы\n",
    "            for i in range(11):\n",
    "                item = cont.select_one(f'#item-{i}')\n",
    "                if item:\n",
    "                    #нужен спан с классом .css-13clqac\n",
    "                    rank_el = item.select_one('button > div > h4 > span.css-13clqac')\n",
    "                    if rank_el:\n",
    "                        rank_text = rank_el.get_text(strip=True)\n",
    "                        #извлекаем число без лишнего\n",
    "                        rank_num = ''.join(filter(str.isdigit, rank_text))\n",
    "                        if rank_num:\n",
    "                            data[rankings_map[i]] = rank_num \n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    input_file = 'the_rankings_2026_full.csv'\n",
    "    output_file = 'parsed_rankings2500_2810.csv' \n",
    "    #здесь можно менять для сохранения в разные файлы параллельных записей\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "        #обрабатываем ошибки\n",
    "    except FileNotFoundError:\n",
    "        print(f'не входного файла')\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f'не читается файл: {e}')\n",
    "        return\n",
    "    \n",
    "    #регулируем!\n",
    "    start_i = 2500  #начало\n",
    "    end_i = 2811   #конец\n",
    "    end_i = min(end_i, len(df))\n",
    "\n",
    "    \n",
    "    #запросная сессия\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    })\n",
    "    \n",
    "    # Список для хранения всех данных\n",
    "    all_data = []\n",
    "    \n",
    "    for idx in range(start_i, end_i):\n",
    "        url = df.iloc[idx]['URL']\n",
    "        \n",
    "        #проверка на пустоту\n",
    "        if pd.isna(url) or str(url).strip() == '':\n",
    "            continue\n",
    "        \n",
    "        print(f'сейчас на {idx+1}/{end_i}: {url}')\n",
    "        \n",
    "        #получаем данные\n",
    "        university_data = parse_rank(url, session)\n",
    "        \n",
    "        if university_data:\n",
    "            all_data.append(university_data)\n",
    "            print(f\"Имя получили\")\n",
    "        else:\n",
    "            print(f'имя не получили')\n",
    "        time.sleep(1)\n",
    "    \n",
    "    #создаём файл\n",
    "    if all_data:\n",
    "        output_df = pd.DataFrame(all_data)\n",
    "        output_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nитог {output_file}\")\n",
    "    else:\n",
    "        print('нет данных')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
