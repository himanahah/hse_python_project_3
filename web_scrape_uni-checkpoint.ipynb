{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World University Rankings Data\n",
    "\n",
    "This notebook will lead you through a simple code to extract the data of university ranking from https://www.timeshighereducation.com/\n",
    "________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "This code tries to extract information from a university ranking website. The concept of collecting data from websites is called web scraping and is used mainly to collect data from websites which do not offer an API to collect data natively. \n",
    "Several tutorials are available to explain the web scraping basics. This notebook is more of a case study. <br />\n",
    "Let's start ......  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "This code assumes that you have python installed on your machine.  Basic knowledge of python is also assumed. Here is a full list of the prerequisites: \n",
    "* python 3.6 or above\n",
    "* Jupyter notebook - or any environment that allows running python\n",
    "* The following python libraries (BeautifulSoup, Selenium, urllib, objectpath and Pandas) \n",
    "* A web browser, I am using chrome 77 here, but you can use other browsers too\n",
    "* Web driver for the browsers you are using, for chrome and chrome based browsers you can download it from here https://chromedriver.chromium.org/downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What data are you trying to get? \n",
    "This is the first question you should ask yourself, before even touching a single key. In our case, we started with the idea of collecting the list of universities with their ranking. To understand how to do so you will need to visit the website itself to understand a bit about it and its webpages. <br/>\n",
    "\n",
    "The page we are tyring to scrap looked something like this \n",
    "\n",
    "![title](img/basic_page_01.PNG)\n",
    "<br/> <br/> <br/> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the page contains some sort of a table that hosts the information we are trying to collect. However collecting the information will depend on the HTML code hidden behind what we can see in the browser window. In chrome to display the HTML code simply press F12. The page should look something like this  \n",
    "\n",
    "![title](img/page_code_02.PNG)\n",
    "<br/> <br/> <br/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the small inspection cursor you can point at elements of the page and find out which part of the HTML represent them. This important because we will only use the HTML to collect the data and not the displayed page in the browser. Once you have identified the part of HTML corresponds with the information we need then we will start scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Let's write some python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard method of using python to request internet pages is through the requests library, however in our particular case this approach will not work, because the website uses AJAX to modify the HTML of the page. This means that the HTML code which you will receive by using requests will only contain an empty template of the table and not the information we are trying to collect. To give the JS code a chance to run and populate the table with the information, we use selenium. Selenium uses browsers to request webpages and then collect the HTML after the page is fully loaded, which will allow us to collect the information we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import json\n",
    "import time\n",
    "\n",
    "# import third party libraries\n",
    "import objectpath\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.timeshighereducation.com/world-university-rankings/latest/world-ranking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "container = driver.find_element(By.CSS_SELECTOR, \"div.css-79elbk tbody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Попытка 1: собрано 26 университетов\n",
      "Попытка 3: собрано 27 университетов\n",
      "Попытка 3: собрано 27 университетов\n",
      "Попытка 4: собрано 29 университетов\n",
      "Попытка 4: собрано 29 университетов\n",
      "Попытка 5: собрано 32 университетов\n",
      "Попытка 5: собрано 32 университетов\n",
      "Попытка 6: собрано 35 университетов\n",
      "Попытка 6: собрано 35 университетов\n",
      "Попытка 7: собрано 37 университетов\n",
      "Попытка 7: собрано 37 университетов\n",
      "Попытка 8: собрано 38 университетов\n",
      "Попытка 8: собрано 38 университетов\n",
      "Попытка 9: собрано 41 университетов\n",
      "Попытка 9: собрано 41 университетов\n",
      "Попытка 10: собрано 43 университетов\n",
      "Попытка 10: собрано 43 университетов\n",
      "Попытка 11: собрано 46 университетов\n",
      "Попытка 11: собрано 46 университетов\n",
      "Попытка 12: собрано 47 университетов\n",
      "Попытка 12: собрано 47 университетов\n",
      "Попытка 13: собрано 51 университетов\n",
      "Попытка 13: собрано 51 университетов\n",
      "Попытка 14: собрано 57 университетов\n",
      "Попытка 14: собрано 57 университетов\n",
      "Попытка 15: собрано 66 университетов\n",
      "Попытка 15: собрано 66 университетов\n",
      "Попытка 16: собрано 78 университетов\n",
      "Попытка 16: собрано 78 университетов\n",
      "Попытка 17: собрано 88 университетов\n",
      "Попытка 17: собрано 88 университетов\n",
      "Попытка 18: собрано 102 университетов\n",
      "Попытка 18: собрано 102 университетов\n",
      "Попытка 19: собрано 115 университетов\n",
      "Попытка 19: собрано 115 университетов\n",
      "Попытка 20: собрано 130 университетов\n",
      "Попытка 20: собрано 130 университетов\n",
      "Попытка 21: собрано 138 университетов\n",
      "Попытка 21: собрано 138 университетов\n",
      "Попытка 23: собрано 139 университетов\n",
      "Попытка 23: собрано 139 университетов\n",
      "Попытка 25: собрано 140 университетов\n",
      "Попытка 25: собрано 140 университетов\n",
      "Попытка 27: собрано 141 университетов\n",
      "Попытка 27: собрано 141 университетов\n",
      "Попытка 28: собрано 142 университетов\n",
      "Попытка 28: собрано 142 университетов\n",
      "Попытка 32: собрано 143 университетов\n",
      "Попытка 32: собрано 143 университетов\n",
      "Попытка 36: собрано 144 университетов\n",
      "Попытка 36: собрано 144 университетов\n",
      "Попытка 43: собрано 145 университетов\n",
      "Попытка 43: собрано 145 университетов\n",
      "Попытка 51: собрано 146 университетов\n",
      "Попытка 51: собрано 146 университетов\n",
      "Попытка 58: собрано 147 университетов\n",
      "Попытка 58: собрано 147 университетов\n",
      "Попытка 69: собрано 148 университетов\n",
      "Попытка 69: собрано 148 университетов\n",
      "Попытка 94: собрано 149 университетов\n",
      "Попытка 94: собрано 149 университетов\n",
      "Новых строк не появляется, завершаем\n",
      "Всего университетов: 149\n",
      "Данные сохранены\n",
      "Новых строк не появляется, завершаем\n",
      "Всего университетов: 149\n",
      "Данные сохранены\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "url = 'https://www.timeshighereducation.com/world-university-rankings/latest/world-ranking'\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "# Закрыть окно куки\n",
    "try:\n",
    "    accept_btn = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Allow all')]\"))\n",
    "    )\n",
    "    driver.execute_script(\"arguments[0].click();\", accept_btn)\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Подождать таблицу\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"table tbody tr\"))\n",
    ")\n",
    "\n",
    "# Собирать уникальные строки\n",
    "seen_ranks = set()\n",
    "all_data = []\n",
    "\n",
    "last_new_count = 0\n",
    "no_change_count = 0\n",
    "scroll_index = 0  # индекс строки для прокрутки\n",
    "\n",
    "for attempt in range(2000):\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"table tbody tr\")\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cells) == 0:\n",
    "            continue\n",
    "        \n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        \n",
    "        if not any(row_data):\n",
    "            continue\n",
    "        \n",
    "        rank = row_data[0] if row_data else \"\"\n",
    "        \n",
    "        if rank and rank not in seen_ranks:\n",
    "            seen_ranks.add(rank)\n",
    "            all_data.append(row_data)\n",
    "    \n",
    "    current_total = len(all_data)\n",
    "    \n",
    "    if current_total > last_new_count:\n",
    "        print(f\"Попытка {attempt + 1}: собрано {current_total} университетов\")\n",
    "        last_new_count = current_total\n",
    "        no_change_count = 0\n",
    "    else:\n",
    "        no_change_count += 1\n",
    "        if no_change_count >= 25:\n",
    "            print(\"Новых строк не появляется, завершаем\")\n",
    "            break\n",
    "    \n",
    "    # Скроллить к строке с индексом scroll_index (примерно в центре или ниже)\n",
    "    if len(rows) > 10:\n",
    "        # Прокрутить строку, которая на 5 позиций от конца видимых\n",
    "        target_index = min(len(rows) - 5, scroll_index)\n",
    "        if target_index < len(rows):\n",
    "            driver.execute_script(\"\"\"\n",
    "                arguments[0].scrollIntoView({block: 'center', inline: 'nearest'});\n",
    "            \"\"\", rows[target_index])\n",
    "        scroll_index += 3  # двигаться по 3 строки за раз\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"Всего университетов: {len(all_data)}\")\n",
    "\n",
    "# Сохранить в CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"the_rankings_2026.csv\", index=False, encoding='utf-8')\n",
    "print(\"Данные сохранены\")\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
